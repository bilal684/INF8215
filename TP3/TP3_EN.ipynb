{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF 8215 - Intelligence artif.: m√©thodes et algorithmes \n",
    "## Fall 2018 - TP3 - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Due date: December 6**\n",
    "\n",
    "**Files to submit:**\n",
    "    * TP3_EN.ipynb filled\n",
    "    * SoftmaxClassifier.py filled\n",
    "    * test_prediction.csv prediction file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The purpose of this lab is to give you an overview of the general course of a machine learning project while familiarizing you with adapted python libraries.\n",
    "\n",
    "\n",
    "In the first part, you will implement a multi-class classification algorithm called **softmax regression** using only **numpy** library and embed it in the **scikit-learn** library.\n",
    "\n",
    "In the second part, you will learn about the **dataset** used for this project. Moreover, you will have to perform the **preprocessing** of these data so that it can be used in conventional machine learning algorithms. To this end, you will use **pandas** and **scikit-learn** libraries.\n",
    "\n",
    "Finally, in the third part, you will compare the efficiency of the model that you have implemented with other models already implemented in **scikit-learn**. Then you will try to improve the performance of the selected algorithm.\n",
    "\n",
    "Once all these steps are done, you will submit your results on the **kaggle** platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "To install **pandas** and **scikit-learn**, the easiest way is to download and install **Anaconda**, which groups together the most used packages for scientific computing and data science.\n",
    "\n",
    "You will find the distribution here: https://www.anaconda.com/download/#linux.\n",
    "\n",
    "Make sure you have **scikit-learn** **20.0**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 1: Competition (2 points)\n",
    "\n",
    "When you finish the lab, you can submit your predictions on **kaggle**, you will get your performance in terms of **log loss**.\n",
    "You can then send me this result by email (laurent.boucaud@polymtl.ca) and join your prediction file on the test set (for verification).\n",
    "\n",
    "A conversation in the forum will be created to keep up to date the best score obtained by one of the teams of the course.\n",
    "\n",
    "As long as no forum is created, **do not send me your performances if they are above 0.8 of log loss**.\n",
    "\n",
    "Once the first best score posted in the forum, **only give me your results if your log loss is lower than the previous best score**.\n",
    "\n",
    "The number of points obtained will be proportional to the ranking of the teams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Softmax Regression (10 points)\n",
    "\n",
    "\n",
    "In this part you will implement **softmax regression**, the **logistic regression** variant which allows you to perform classification for a class number greater than 2.\n",
    "\n",
    "The code to be completed is in the **SoftmaxClassifier.py** file.\n",
    "\n",
    "**For this exercise, the constraint is to use only the numpy library **\n",
    "\n",
    "## Sklearn encapsulation\n",
    "\n",
    "\n",
    "The class **SoftmaxClassifier** inherits from the **BaseEstimator** and **ClassifierMixin** classes from **scikit-learn** which will allow us to easily use the tools provided by scikit-learn with our classifier later.\n",
    "\n",
    "For compatibility, the classifier necessarily implements the methods:\n",
    "\n",
    "* **fit**: responsible for training the model\n",
    "* **predict_proba**: Predicts the probability of each class for each example in the dataset provided.\n",
    "* **predict**: Predicts the class for each example in the provided dataset.\n",
    "* **score**: quantifies the difference between the predicted classes and the actual classes for the dataset provided\n",
    "\n",
    "\n",
    "## Train/Test set:\n",
    "\n",
    "When one wants to test the performance of learning a machine learning algorithm, one **does not test it on the data used for learning**.\n",
    "\n",
    "Indeed, what interests us is that our algorithm is able to generalize its predictions to the data that it has never seen.\n",
    "\n",
    "To illustrate, if we test an algorithm on the training data, we test its ability to **learn by heart** the dataset and not to **generalize**.\n",
    "\n",
    "Therefore, when receiving a new dataset, the first thing to do is to **split it into two parts**: a **train set** (**70-80%** of the dataset) and a **test set** (**20-30%** of the dataset).\n",
    "\n",
    "All **data processing** and **learning algorithms** should be learned only on the training set and then applied to the test set.\n",
    "\n",
    "By doing so, the lack of prior knowledge of the test set during training is ensured.\n",
    "\n",
    "## Gradient descent\n",
    "\n",
    "Gradient descent is an algorithm that allows finding the optimal solution of a certain number of problems. The principle is as follows: we define a **cost function J** that characterizes the problem.\n",
    "This function depends on a set of **$\\theta$** parameters. Gradient descent seeks to **minimize** the cost function by **iteratively modifying** the parameters.\n",
    "\n",
    "### Gradient\n",
    "\n",
    "The cost function gradient for a given $\\theta$, is the direction in which $\\theta$ must be modified to reduce the value of the cost function.\n",
    "\n",
    "The cost function is minimal when the gradient is zero.\n",
    "\n",
    "Concretely, we initialize $\\theta$ randomly, and we do at each iteration a step to reduce the cost function until convergence of the algorithm to a minimum of the cost function.\n",
    "\n",
    "### Learning rate\n",
    "\n",
    "\n",
    "The learning rate represents the size of the step that will be made in the direction of the gradient.\n",
    "The larger it is, the faster the convergence, but there is a risk that the algorithm will diverge.\n",
    "\n",
    "The smaller it is, the slower the convergence.\n",
    "\n",
    "### Batch gradient descent\n",
    "\n",
    "There are several gradient descent algorithms. We will use Batch gradient descent.\n",
    "\n",
    "In this algorithm, before updating $\\theta$, we calculate the gradients on all the training examples.\n",
    "\n",
    "### Epoch\n",
    "\n",
    "This is a step of the gradient descent, a single gradient update.\n",
    "\n",
    "### Bias/Variance tradeoff\n",
    "\n",
    "When training a machine learning algorithm we look for a tradeoff between **bias** and **variance**.\n",
    "\n",
    "A model with a **strong bias**, is a model that is **too simple** for the given data structure (e.g., a linear model for quadratic data), this limits the capacity of the model to generalize. We also call bias  **underfitting**.\n",
    "\n",
    "A model with a **high variance** means that it is sensitive to small variations in training data, this corresponds to **overfitting**, i.e., the model is too close to the structure of the training set which **limits its ability to generalize**.\n",
    "\n",
    "A model with a **significant bias** will have a **poor** performance over the **training set**.\n",
    "A model with a **significant variance** will have a much worse **performance** on the entire **test set** than on the  **train set**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot-encoding\n",
    "\n",
    "In machine learning to represent a vector of categorical data, we use one-hot encoding.\n",
    "\n",
    "For a vector containing 5 examples and 3 different categories, it is represented as a matrix of size 5 by 3. This matrix is entirely filled with 0 except for the index corresponding to the number of the class for each example.\n",
    "\n",
    "\n",
    "For example\n",
    "$ y = \\left(\\begin{array}{cc} \n",
    "1 \\\\\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "3 \\\\\n",
    "2 \\\\\n",
    "\\end{array}\\right) $\n",
    "\n",
    "becomes:\n",
    "\n",
    "$ yohe =  \\left(\\begin{array}{cc} \n",
    "1. & 0. & 0.\\\\\n",
    "1. & 0. & 0.\\\\\n",
    "0. & 1. & 0.\\\\\n",
    "0. & 0. & 1.\\\\\n",
    "0. & 1. & 0.\\\\\n",
    "\\end{array}\\right) $\n",
    "\n",
    "\n",
    "#### Question 1 (1 point)\n",
    "Implement the **_one_hot** method in SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _one_hot(self,y):\n",
    "    tmp=np.zeros((y.shape[0],self.nb_classes))\n",
    "    for i in range(y.shape[0]):\n",
    "        invoked_classc=int(y[i][0])\n",
    "        tmp[i][invoked_classc]=1\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight matrix\n",
    "\n",
    "Let $ X_{m * n} $ be the example matrix and $ \\Theta _{n*K} $ the weight matrix with:\n",
    "\n",
    "* **m** number of examples\n",
    "* **n** number of features\n",
    "* **k** number of target classes\n",
    "\n",
    "\n",
    "\n",
    "It is common to add an additional column to X, this column is filled with 1. To take into account this change, we must add a line to the matrix $\\Theta$.\n",
    "\n",
    "We get X_bias$_{m*(n+1)}$ et $ \\Theta _{(n+1)*K} $\n",
    "\n",
    "\n",
    "Intuitively, each class K is associated with a $\\theta$ column.\n",
    "\n",
    "We denote by $\\theta_k$ (n+1 dimension vector) the weight column associated with the prediction of class k .\n",
    "\n",
    "$\\Theta$ = [$\\theta_0$,$\\theta_1$... $\\theta_k$ ... $\\theta_n$ ]\n",
    "\n",
    "Thus $ z = x * \\Theta $ gives a vector of dimension K which are **logits** associated with x for each class.\n",
    "\n",
    "#### Question 2 (1 point)\n",
    "\n",
    "In the **fit** function in SoftmaxClassifier.py instantiate X_bias and initialize $\\Theta$  randomly. (line 74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X, y=None):\n",
    "\n",
    "    prev_loss = np.inf\n",
    "    self.losses_ = []\n",
    "\n",
    "    self.nb_feature = X.shape[1]\n",
    "    self.nb_classes = len(np.unique(y))\n",
    "    tmp=np.ones((X.shape[0],1))\n",
    "    X_bias = np.concatenate((tmp,X),axis=1)\n",
    "    self.theta_=np.random.rand(self.nb_feature+1,self.nb_classes)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "\n",
    "We want to convert the logit vector **z** obtained in the previous part into a **probability vector**.\n",
    "\n",
    "For this we define the **softmax function**:\n",
    "\n",
    "\n",
    "$$ \\hat{p_x}^k = softmax(z)_k = \\frac{exp(z_k)}{\\sum_{\\substack{1<j<K}} exp(z_j)} $$\n",
    "\n",
    "\n",
    "Intuitively, for a logit of z, $z_k$, we take the exponential of this value and divide it by the sum of the exponentials of each logit of the vector **z**. We get $\\hat{p_x}^k$ the probability that the example **x** belongs to the class **k**.\n",
    "\n",
    "The operation is repeated for each logit of the vector **z**.\n",
    "\n",
    "We thus obtain a probability vector $\\hat{p_x}$ for an example **x**.\n",
    "\n",
    "The division makes it possible to make the sum of the terms of the vector $\\hat{p_x}$ equal to 1 which is indispensable for probabilities.\n",
    "\n",
    "#### Question 3 (1 point)\n",
    "Implement  **_softmax** method in SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _softmax(self,z):\n",
    "    prob_vector=np.exp(z)\n",
    "    tmp_sum=np.sum(prob_vector,axis=1)\n",
    "    tmp_sum=tmp_sum.reshape(tmp_sum.shape[0],1)\n",
    "    return prob_vector/tmp_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 (1 point)\n",
    "\n",
    "Using the **_ softmax** function of question 3, implement the **predict_proba** and **predict** methods in SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, X, y=None):\n",
    "    try:\n",
    "        getattr(self, \"theta_\")\n",
    "    except AttributeError:\n",
    "        raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "    predicted_prob=self.predict_proba(X,None)\n",
    "    result=np.argmax(predicted_prob,axis=1)\n",
    "    return result.reshape(result.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de co√ªt Log loss\n",
    "\n",
    "Let log loss (ou cross entropy) be the cost function:\n",
    "\n",
    "$$ J( \\Theta) = \\frac{-1}{m}\\sum_{\\substack{1<i<m}} \\sum_{\\substack{1<k<K}} y_k^i log( \\hat{p_k}^i ) $$\n",
    "\n",
    "with:\n",
    "* **K** number of classes\n",
    "* **m** number of examples\n",
    "* $ \\hat{p_k}^i  $  probability that example i be of target class k\n",
    "* $y_k^i$ is 1 if the target class of example i is k, 0 otherwise\n",
    "\n",
    "**Implementation detail:** Cost function is not defined for probabilities taking values 0. or 1., we must ensure that given $\\epsilon$, probabilities are in  [$\\epsilon$, 1. - $\\epsilon$].\n",
    "#### Question 5 (1 point)\n",
    "\n",
    "Implement the **_ cost_function** method in SoftmaxClassifier.py by taking into account the **implementation detail** (self.eps variable) and use it to calculate the **loss** variable in the **fit** method (line 84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cost_function(self,probabilities, y ):\n",
    "    m=probabilities.shape[0]\n",
    "    p_processed=np.clip(probabilities,self.eps,1-self.eps)\n",
    "    cost_sum=0\n",
    "    y_one_hot=self._one_hot(y)\n",
    "    for i in range(m):\n",
    "        c = np.argmax(y_one_hot[i,:]) # class\n",
    "        cost_sum += np.log(p_processed[i,c])\n",
    "    return (-1/m)*cost_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function gradient\n",
    "\n",
    "The **gradient of J** with respect to $\\theta_k$ is :\n",
    "\n",
    "\n",
    "$$ \\Delta_{\\theta_k}J( \\Theta) = \\frac{1}{m} \\sum_{\\substack{1<i<m}}( \\hat{p_k}^i - y_k^i)x^i  $$\n",
    "\n",
    "with:\n",
    "* **K** number of target classes\n",
    "* **m** number of examples\n",
    "* $ \\hat{p_k}^i  $  probability that example i is of class k\n",
    "* $y_k^i$ is 1 if example i target class is k, 0 otherwise\n",
    "\n",
    "\n",
    "We can rewrite it as matrices, the **gradient of J** with respect to $\\Theta$** is :\n",
    "$$ \\Delta_J( \\Theta) = \\frac{1}{m} X_{bias}^T *( \\hat{p} - y_{ohe}) $$\n",
    "\n",
    "with:\n",
    "\n",
    "* $\\hat{p}$ predicted probability matrix for every example and every class\n",
    "* $y_{ohe}$ one-hot encoded y\n",
    "* $X_{bias}^T$  Transposed matrix of $X_{bias}$\n",
    "* **\\*** Dot product\n",
    "\n",
    "#### Question 6 (1 point)\n",
    "Implement  **_get_gradient** method in SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_gradient(self,X,y, probas):\n",
    "    m=y.shape[0]\n",
    "    tmp=np.ones((X.shape[0],1))\n",
    "    X_bias = np.concatenate((tmp,X),axis=1)\n",
    "    gradients_costfunction=(1/m)*np.dot((np.transpose(X_bias)),probas-self._one_hot(y))\n",
    "    return gradients_costfunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights update\n",
    "\n",
    "When the gradient has been computed, we must update the weights with these gradients.\n",
    "\n",
    "\n",
    "$$ \\Theta  = \\Theta - \\gamma \\Delta J( \\Theta) $$\n",
    "\n",
    "\n",
    "with:\n",
    "* $\\Theta$ weight matrix\n",
    "* $\\gamma$  learning rate\n",
    "* $\\Delta J( \\Theta)$ gradient of $J( \\Theta)$ with respect to $\\Theta$\n",
    "\n",
    "#### Question 7 (1 point)\n",
    "Update **self.theta_** in the **fit** method in SoftmaxClassifier.py (line 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X, y=None):\n",
    "\n",
    "    prev_loss = np.inf\n",
    "    self.losses_ = []\n",
    "\n",
    "    self.nb_feature = X.shape[1]\n",
    "    self.nb_classes = len(np.unique(y))\n",
    "\n",
    "    tmp = np.ones((X.shape[0], 1))\n",
    "    X_bias = np.concatenate((tmp, X), axis=1)\n",
    "    self.theta_ = np.random.rand(self.nb_feature + 1, self.nb_classes)\n",
    "\n",
    "    for epoch in range(self.n_epochs):\n",
    "\n",
    "        # logits =\n",
    "        probabilities = self.predict_proba(X)\n",
    "\n",
    "        loss = self._cost_function(probabilities, y)\n",
    "        gradient = self._get_gradient(X, y, probabilities)\n",
    "        self.theta_ = self.theta_ - self.lr * gradient\n",
    "\n",
    "        self.losses_.append(loss)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "To limit **overfitting**, we use the regularization, we add a term to the function of cost $J( \\Theta)$.\n",
    "\n",
    "This term will add constraints on the weight of the model during training.\n",
    "We will use the **L2** regularization:\n",
    "\n",
    "\n",
    "$$ L2(\\Theta) = \\alpha \\sum_{\\substack{1<=i<n}} \\sum_{\\substack{0<=k<K}} \\theta_{i,k}^2 $$ \n",
    "\n",
    "with:\n",
    "\n",
    "* $\\alpha$ regularization coefficient\n",
    "\n",
    "**Note:** The first sum does not start at 0 but at 1 because we do not adjust the weights associated with the X bias column.\n",
    "\n",
    "Adding this term leads the model to learn the data while keeping its weight as small as possible.\n",
    "\n",
    "\n",
    "\n",
    "#### Question 8 (1 point)\n",
    "\n",
    "Modify the methods **_ get_gradient** and **_ cost_function** to take into account the regularization when the boolean self.regularization is true in SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_gradient(self,X,y, probas):\n",
    "    if self.regularization:\n",
    "        m=y.shape[0]\n",
    "        tmp=np.ones((X.shape[0],1))\n",
    "        X_bias = np.concatenate((tmp,X),axis=1)\n",
    "        tmp_labels=self._one_hot(y)\n",
    "        tmp_subtraction=probas-tmp_labels\n",
    "        gradients_costfunction=(1/m)*(np.dot((np.transpose(X_bias)),tmp_subtraction))\n",
    "        gradients_costfunction[1:,:]+=2*self.alpha*self.theta_[1:,:]/m\n",
    "    else:\n",
    "        m=y.shape[0]\n",
    "        tmp=np.ones((X.shape[0],1))\n",
    "        X_bias = np.concatenate((tmp,X),axis=1)\n",
    "        gradients_costfunction=(1/m)*np.dot((np.transpose(X_bias)),probas-self._one_hot(y))\n",
    "    return gradients_costfunction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9 (1 point)\n",
    "\n",
    "The regularization term is used only during training. When one wants to evaluate the performance of the model **after training**, one uses the **non-regulated** cost function.\n",
    "\n",
    "Implement the **score** function that evaluates the quality of the prediction **after training** in SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(self, X, y=None):\n",
    "    sum_number=X.shape[0]\n",
    "    result=self.predict(X,y)\n",
    "    tmp=result-y\n",
    "    right_number=sum(tmp==0)\n",
    "    return right_number[0]/sum_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping\n",
    "\n",
    "Too many **epochs** can result in **overfitting**.\n",
    "To overcome this problem, we can use the mechanism of **early stopping**.\n",
    "This aims to stop the training if the difference in the cost function between two **consecutive epochs** is less than a defined **threshold**.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Question 10 (1 point)\n",
    "\n",
    "Finish implementing the **fit** function by adding the **early stopping** mechanism when the **self.early_stopping** boolean is true. The threshold is given by the **self.threshold variable** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X, y=None):\n",
    "\n",
    "    prev_loss = np.inf\n",
    "    self.losses_ = []\n",
    "\n",
    "    self.nb_feature = X.shape[1]\n",
    "    self.nb_classes = len(np.unique(y))\n",
    "\n",
    "    tmp = np.ones((X.shape[0], 1))\n",
    "    X_bias = np.concatenate((tmp, X), axis=1)\n",
    "    self.theta_ = np.random.rand(self.nb_feature + 1, self.nb_classes)\n",
    "\n",
    "    for epoch in range(self.n_epochs):\n",
    "\n",
    "        # logits =\n",
    "        probabilities = self.predict_proba(X)\n",
    "\n",
    "        loss = self._cost_function(probabilities, y)\n",
    "        gradient = self._get_gradient(X, y, probabilities)\n",
    "        self.theta_ = self.theta_ - self.lr * gradient\n",
    "        self.losses_.append(loss)\n",
    "        if self.early_stopping:\n",
    "            if epoch > 1 and abs(self.losses_[epoch] - self.losses_[epoch - 1]) < self.threshold:\n",
    "                break\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the solution:\n",
    "\n",
    "The code below imports the **iris** multiclass  classification dataset available on sklearn. The data is divided into two parts, the training set and the test set, and then they are normalized.\n",
    "\n",
    "The classifier implemented in the **SoftmaxClassifier.py** file is imported and then trained on the training set and tested on the test set.\n",
    "\n",
    "The purpose of this part is just to check your implementation **when you are sure your code is working**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from SoftmaxClassifier import SoftmaxClassifier\n",
    "\n",
    "# load dataset\n",
    "data,target =load_iris().data,load_iris().target\n",
    "\n",
    "# split data in train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split( data, target, test_size=0.33, random_state=42)\n",
    "\n",
    "# standardize columns using normal distribution\n",
    "# fit on X_train and not on X_test to avoid Data Leakage\n",
    "s = StandardScaler()\n",
    "X_train = s.fit_transform(X_train)\n",
    "X_test = s.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from SoftmaxClassifier import SoftmaxClassifier\n",
    "\n",
    "# import the custom classifier\n",
    "cl = SoftmaxClassifier()\n",
    "y_train=y_train.reshape((y_train.shape[0],1))\n",
    "# train on X_train and not on X_test to avoid overfitting\n",
    "train_p = cl.fit_predict(X_train,y_train)\n",
    "test_p = cl.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get relatively close values for the test and training set, and they are at least greater than 0.8, your model should be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : (0.86956521739130432, 0.84705882352941175, 0.84137931034482749, None)\n",
      "test : (0.88888888888888884, 0.8222222222222223, 0.81212121212121213, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# display precision, recall and f1-score on train/test set\n",
    "print(\"train : \"+ str(precision_recall_fscore_support(y_train, train_p,average = \"macro\")))\n",
    "print(\"test : \"+ str(precision_recall_fscore_support(y_test, test_p,average = \"macro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.1843274719843393, 3.6347058572777149, 2.6539175829816815, 2.0318695541866796, 1.6365931871047432, 1.3849971288497884, 1.224618299051647, 1.1222462351476659, 1.0568120364897258, 1.0149258887373094, 0.98806623568513829, 0.97080367427808389, 0.95967578447860613, 0.95247287274970194, 0.94778383146001954, 0.94470701824496117, 0.94266600702053971, 0.9412920770470482, 0.94034921860327381, 0.93968624783993826, 0.93920621862355724, 0.93884687672558553, 0.93856816648820918, 0.93834424331832822, 0.93815836577654377, 0.93799962839496664, 0.93786087137767393, 0.93773734287598343, 0.93762584258178461, 0.93752417319836256, 0.93743078887650577, 0.9373445696812498, 0.93726467671789404, 0.93719045889398422, 0.93712139274971806, 0.93705704347702246, 0.93699703952551316, 0.93694105593022892, 0.93688880324679713, 0.93684002009985201, 0.93679446806723821, 0.93675192808115448, 0.93671219782091009, 0.93667508975985714, 0.93664042964932148, 0.93660805529941382, 0.93657781556596131, 0.93654956948444645, 0.93652318551217251, 0.93649854085291018, 0.9364755208467288, 0.93645401841312292, 0.93643393353908766, 0.93641517280610698, 0.93639764895152822, 0.93638128046081681, 0.93636599118787045, 0.93635171000106143, 0.93633837045298218, 0.93632591047217173, 0.93631427207523155, 0.93630340109793719, 0.9362932469440487, 0.93628376235063149]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(cl.losses_)\n",
    "plt.show()\n",
    "print(cl.losses_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preprocessing (8 points)\n",
    "\n",
    "##  Kaggle \n",
    "\n",
    "Kaggle is a website dedicated to machine learning. There is a large number of datasets.\n",
    "Competitions are organized by companies and organisations. These provide a dataset and a goal. The \"kagglers\" who participate in these competitions submit their results online. There are often prices or jobs for those who get the best results.\n",
    "\n",
    "This is a good way to develop machine learning skills on real datasets.\n",
    "\n",
    "You can create an account if you want to compare your results to those already online for the dataset we are going to study.\n",
    "\n",
    "You can create an account here: https://www.kaggle.com/\n",
    "\n",
    "## Austin Animal Center Shelter Animal Outcomes dataset\n",
    "The dataset that we will use is the \"Animal Outcomes dataset\" available at the following address: https://www.kaggle.com/c/shelter-animal-outcomes.\n",
    "\n",
    "This is a problem of **multi-class classification** where animals are collected in a shelter after being abandoned, the purpose is to predict how they will \"leave\" the place:\n",
    "* Adoption\n",
    "* Back to the owner\n",
    "* Death\n",
    "* Euthanasia\n",
    "* Transfer to another center\n",
    "\n",
    "For more information on data, go to kaggle.\n",
    "\n",
    "## Structure of a machine learning project\n",
    "\n",
    "The goal of the this part of the lab is to make you study a simplified version of a complete machine learning project:\n",
    "\n",
    "1. Data cleaning, missing value processing\n",
    "2. Formatting Data for Use in Machine Learning Algorithms\n",
    "3. Feature engineering transformation or feature combinations between them\n",
    "4. Comparison of the performances of the different choices made during the data processing\n",
    "5. Comparison of the performances of different models (including the one implemented in the first part)\n",
    "6. Optimization of hyper-parameters\n",
    "\n",
    "\n",
    "## Scikit-learn\n",
    "http://scikit-learn.org/stable/\n",
    "\n",
    "It is a machine learning and data mining library, it offers tools for data analysis and processing, classical machine learning algorithms such as neural networks, logistic regression, SVM or other, finally tools to compare models between them such as cross validation.\n",
    "\n",
    "## Pandas\n",
    "\n",
    "A library to store and manipulate data easily\n",
    "\n",
    "The two basic elements of pandas are the dataframe and the series.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.html\n",
    "\n",
    "## Data processing tutorial\n",
    "\n",
    "** Before continuing the lab **, familiarize yourself with the **pre-processing data**, **pandas** and **scikit-learn**, a tutorial is available in the file: *data_processing_tutorial.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "#### Load train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PATH = \"data/\"\n",
    "X_train = pd.read_csv(PATH + \"train.csv\")\n",
    "X_test = pd.read_csv(PATH + \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useless features removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns = [\"OutcomeSubtype\",\"AnimalID\"])\n",
    "X_test = X_test.drop(columns = [\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_train.drop(columns = [\"OutcomeType\"]),X_train[\"OutcomeType\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first 5  examples of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hambone</td>\n",
       "      <td>2014-02-12 18:22:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Shetland Sheepdog Mix</td>\n",
       "      <td>Brown/White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emily</td>\n",
       "      <td>2013-10-13 12:44:00</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Cream Tabby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pearce</td>\n",
       "      <td>2015-01-31 12:28:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Pit Bull Mix</td>\n",
       "      <td>Blue/White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-07-11 19:09:00</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>3 weeks</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Blue Cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-11-15 12:52:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Lhasa Apso/Miniature Poodle</td>\n",
       "      <td>Tan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name             DateTime AnimalType SexuponOutcome AgeuponOutcome  \\\n",
       "0  Hambone  2014-02-12 18:22:00        Dog  Neutered Male         1 year   \n",
       "1    Emily  2013-10-13 12:44:00        Cat  Spayed Female         1 year   \n",
       "2   Pearce  2015-01-31 12:28:00        Dog  Neutered Male        2 years   \n",
       "3      NaN  2014-07-11 19:09:00        Cat    Intact Male        3 weeks   \n",
       "4      NaN  2013-11-15 12:52:00        Dog  Neutered Male        2 years   \n",
       "\n",
       "                         Breed        Color  \n",
       "0        Shetland Sheepdog Mix  Brown/White  \n",
       "1       Domestic Shorthair Mix  Cream Tabby  \n",
       "2                 Pit Bull Mix   Blue/White  \n",
       "3       Domestic Shorthair Mix   Blue Cream  \n",
       "4  Lhasa Apso/Miniature Poodle          Tan  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first 5  examples of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summer</td>\n",
       "      <td>2015-10-12 12:15:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>10 months</td>\n",
       "      <td>Labrador Retriever Mix</td>\n",
       "      <td>Red/White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cheyenne</td>\n",
       "      <td>2014-07-26 17:59:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>2 years</td>\n",
       "      <td>German Shepherd/Siberian Husky</td>\n",
       "      <td>Black/Tan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gus</td>\n",
       "      <td>2016-01-13 12:20:00</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Brown Tabby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pongo</td>\n",
       "      <td>2013-12-28 18:12:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>4 months</td>\n",
       "      <td>Collie Smooth Mix</td>\n",
       "      <td>Tricolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skooter</td>\n",
       "      <td>2015-09-24 17:59:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Miniature Poodle Mix</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name             DateTime AnimalType SexuponOutcome AgeuponOutcome  \\\n",
       "0    Summer  2015-10-12 12:15:00        Dog  Intact Female      10 months   \n",
       "1  Cheyenne  2014-07-26 17:59:00        Dog  Spayed Female        2 years   \n",
       "2       Gus  2016-01-13 12:20:00        Cat  Neutered Male         1 year   \n",
       "3     Pongo  2013-12-28 18:12:00        Dog    Intact Male       4 months   \n",
       "4   Skooter  2015-09-24 17:59:00        Dog  Neutered Male        2 years   \n",
       "\n",
       "                            Breed        Color  \n",
       "0          Labrador Retriever Mix    Red/White  \n",
       "1  German Shepherd/Siberian Husky    Black/Tan  \n",
       "2          Domestic Shorthair Mix  Brown Tabby  \n",
       "3               Collie Smooth Mix     Tricolor  \n",
       "4            Miniature Poodle Mix        White  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first 5  examples of the target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Return_to_owner\n",
       "1         Euthanasia\n",
       "2           Adoption\n",
       "3           Transfer\n",
       "4           Transfer\n",
       "Name: OutcomeType, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "To save you time, some of the columns (Name, DateTime, color) have already been processed.\n",
    "\n",
    "\n",
    "Using the tutorial provided, you must write a complete transformation pipeline for each of the remaining columns in the dataset (AgeuponOutcome, AnimalType, SexuponOutcome, Breed).\n",
    "\n",
    "You are **free** of your choices, but you must **justify** column by column.\n",
    "For example, you can choose to combine columns with each other, separate a column or eliminate a column completely if you correctly justify it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The already preprocessed part of the dataset is loaded in **X_train1** and **X_test1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = pd.read_csv(\"data/train_preprocessed.csv\")\n",
    "X_test1 = pd.read_csv(\"data/test_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "      <th>HasName</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.973624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.421532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.973624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.471381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.868974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Color  HasName  Month  Day  Hour\n",
       "0  0.973624      1.0    2.0  1.0   3.0\n",
       "1 -1.421532      1.0   10.0  1.0   2.0\n",
       "2  0.973624      1.0    1.0  3.0   2.0\n",
       "3 -1.471381      0.0    7.0  1.0   3.0\n",
       "4 -0.868974      0.0   11.0  1.0   2.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset part you have to process is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns = [\"Color\",\"Name\",\"DateTime\"])\n",
    "X_test = X_test.drop(columns = [\"Color\",\"Name\",\"DateTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>Breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Shetland Sheepdog Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Pit Bull Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>3 weeks</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Lhasa Apso/Miniature Poodle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AnimalType SexuponOutcome AgeuponOutcome                        Breed\n",
       "0        Dog  Neutered Male         1 year        Shetland Sheepdog Mix\n",
       "1        Cat  Spayed Female         1 year       Domestic Shorthair Mix\n",
       "2        Dog  Neutered Male        2 years                 Pit Bull Mix\n",
       "3        Cat    Intact Male        3 weeks       Domestic Shorthair Mix\n",
       "4        Dog  Neutered Male        2 years  Lhasa Apso/Miniature Poodle"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Question 11: AgeuponOutcome (1 point)\n",
    "\n",
    "Pour la colonne Age Upon Outcome, nous avons d√©cid√© de transformer toutes les donn√©es sur une m√™me base, soit en semaine. Ce choix a √©t√© fais al√©atoirement, on aurait pu les mettre en jours, en mois ou en ann√©e. Ce qu'il faut comprendre c'est qu'il y a 52.1428228589286 semaines par an et 4.34524 semaines par mois. Une fois les donn√©es convertit sur une m√™me base, nous les normalisons √† l'aide du StandardScaler. Comme indiqu√© dans le tutoriel de ce TP, la normalisation est n√©cessaire pour les donn√©es de cette colonne sur une m√™me √©chelle pour que cette colonne n'impacte pas les autres colonnes lors de l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline#, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from preprocessing import TransformationWrapper\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def convertAgeUponOutcomeToWeeks(text):\n",
    "    if (not isinstance(text, str)) and math.isnan(text):\n",
    "       return 0.0\n",
    "    else:\n",
    "        number, timeFrame = text.split(\" \")\n",
    "        if timeFrame.lower() == \"year\" or timeFrame.lower() == \"years\":\n",
    "            return float(number) * 52.1428228589286 #52 weeks per year\n",
    "        elif timeFrame.lower() == \"month\" or timeFrame.lower() == \"months\":\n",
    "            return float(number) * 4.34524 #4 weeks per month\n",
    "        elif timeFrame.lower() == \"week\" or timeFrame.lower() == \"weeks\":\n",
    "            return float(number) # 1 week per week\n",
    "        elif timeFrame.lower() == \"day\" or timeFrame.lower() == \"days\":\n",
    "            return float(number) * 1.0/7.0 #because there are 7 days per week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 12: AnimalType (1 point)\n",
    "\n",
    "Pour cette colonne, nous avons remarqu√© qu'il y avait que deux valeurs dans cette colonne, soit \"Dog\" ou \"Cat\". Ainsi, nous avons choisi de repr√©senter ces donn√©es sous forme binaires. La valeur \"Dog\" sera repr√©sent√© par la valeur \"0\". La valeur \"1\" pour \"Cat\". Ce choix a √©t√© fait arbitrairement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertAnimalType(text):\n",
    "    if text == 'Dog':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 13: SexuponOutcome (1 point)\n",
    "\n",
    "Pour la colonne SexuponOutcome, nous avons remarqu√© qu'il y avait cinq diff√©rentes valeurs, soit \"Neutered Male\", \"Spayed Female\", \"Intact Male\", \"Intact Female\" et \"Unknown\". Ainsi, ces valeurs ont √©t√© respectivement chang√© par 0, 1, 2, 3, et 4. √âvidemment, comme cette colonne est cat√©gorique, il est n√©cessaire d'appliquer l'encodage \"One Hot Encoding\", pour √©viter que certains algorithmes d'apprentissage prennent en compte l'ordre num√©rique des cat√©gories, tel qu'expliqu√© dans le tutoriel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertSexUponOutcome(text):\n",
    "    if text == \"Neutered Male\":\n",
    "        return 0\n",
    "    elif text == \"Spayed Female\":\n",
    "        return 1\n",
    "    elif text == \"Intact Male\":\n",
    "        return 2\n",
    "    elif text == \"Intact Female\":\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 14: Breed (1 point)\n",
    "\n",
    "Pour Breed, nous avons remarqu√© qu'il existait plus de 1300 valeurs diff√©rentes. Il n'est donc pas judicieux de repr√©senter ces 1300 valeurs sous forme de 1300 cat√©gorie diff√©rentes comme nous l'avons fait pour la colonne \"SexUponOutcome\" √† la question pr√©c√©dente. La matrice r√©sultant serait beaucoup trop grande. Ainsi, nous avons accepter de perdre de l'information sur cette colonne en extrayant uniquement le fait qu'un animal soit un hybride entre deux animal ou non (un mix ou non). Au moins, nous aurons extrait de l'information de cette colonne plut√¥t que de l'ignorer compl√®tement. Ainsi, pour d√©terminer si l'animal est un mix ou non, nous avons v√©rifi√© si l'entr√©e dans cette colonne contenait le mot \"mix\" ou si elle contenait un s√©parateur \"/\". Si l'animal est un mix, alors on mettra la valeur \"1\" √† la ligne correspondante. Sinon, on mettre un \"0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertBreed(text):\n",
    "    text = text.lower()\n",
    "    if \"mix\" in text or \"/\" in text:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "**Question 15: Fill the pipeline below (4 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import TransformationWrapper\n",
    "from preprocessing import LabelEncoderP\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "pipeline_ageuponoutcome_changeToWeeks = Pipeline(\n",
    "    [\n",
    "        ('ConvertAgeUponOutcomeToWeeks', TransformationWrapper(transformation=convertAgeUponOutcomeToWeeks)),\n",
    "        ('Normalization', StandardScaler())\n",
    "])\n",
    "\n",
    "pipeline_AnimalType_ChangeAnimalType = Pipeline(\n",
    "    [\n",
    "       ('ConvertAnimalType', TransformationWrapper(transformation=convertAnimalType))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline_SexuponOutcome_ChangeSexUponOutcome = Pipeline(\n",
    "    [\n",
    "        ('ConvertSexUponOutcome', TransformationWrapper(transformation=convertSexUponOutcome)),\n",
    "        ('OneHotEncoding', OneHotEncoder(categories='auto', sparse=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline_changeBreed = Pipeline(\n",
    "    [\n",
    "        ('ChangeBreed', TransformationWrapper(transformation=convertBreed))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "full_pipeline = ColumnTransformer(\n",
    "    [\n",
    "        (\"AgeuponOutcome\", pipeline_ageuponoutcome_changeToWeeks, \"AgeuponOutcome\"),\n",
    "        (\"AnimalType\", pipeline_AnimalType_ChangeAnimalType, \"AnimalType\"),\n",
    "        (\"SexuponOutcome\", pipeline_SexuponOutcome_ChangeSexUponOutcome, \"SexuponOutcome\"),\n",
    "        ('breed', pipeline_changeBreed, \"Breed\")\n",
    "    ], remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>Neutered Male</th>\n",
       "      <th>Spayed Female</th>\n",
       "      <th>Intact Male</th>\n",
       "      <th>Intact Female</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Mix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.396515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.396515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.059276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.714351</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.059276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AgeuponOutcome  AnimalType  Neutered Male  Spayed Female  Intact Male  \\\n",
       "0       -0.396515         0.0            1.0            0.0          0.0   \n",
       "1       -0.396515         1.0            0.0            1.0          0.0   \n",
       "2       -0.059276         0.0            1.0            0.0          0.0   \n",
       "3       -0.714351         1.0            0.0            0.0          1.0   \n",
       "4       -0.059276         0.0            1.0            0.0          0.0   \n",
       "\n",
       "   Intact Female  Unknown  Mix  \n",
       "0            0.0      0.0  1.0  \n",
       "1            0.0      0.0  1.0  \n",
       "2            0.0      0.0  1.0  \n",
       "3            0.0      0.0  1.0  \n",
       "4            0.0      0.0  1.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"AgeuponOutcome\", \"AnimalType\", \"Neutered Male\", \"Spayed Female\", \"Intact Male\", \"Intact Female\", \"Unknown\", \"Mix\"]\n",
    "X_train_prepared = pd.DataFrame(full_pipeline.fit_transform(X_train),columns = columns)\n",
    "X_test_prepared = pd.DataFrame(full_pipeline.fit_transform(X_test),columns = columns)\n",
    "X_train_prepared.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>Neutered Male</th>\n",
       "      <th>Spayed Female</th>\n",
       "      <th>Intact Male</th>\n",
       "      <th>Intact Female</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Mix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.439590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.042708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.382893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.609683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.042708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AgeuponOutcome  AnimalType  Neutered Male  Spayed Female  Intact Male  \\\n",
       "0       -0.439590         0.0            0.0            0.0          0.0   \n",
       "1       -0.042708         0.0            0.0            1.0          0.0   \n",
       "2       -0.382893         1.0            1.0            0.0          0.0   \n",
       "3       -0.609683         0.0            0.0            0.0          1.0   \n",
       "4       -0.042708         0.0            1.0            0.0          0.0   \n",
       "\n",
       "   Intact Female  Unknown  Mix  \n",
       "0            1.0      0.0  1.0  \n",
       "1            0.0      0.0  1.0  \n",
       "2            0.0      0.0  1.0  \n",
       "3            0.0      0.0  1.0  \n",
       "4            0.0      0.0  1.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_prepared.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate both part of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "      <th>HasName</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>Neutered Male</th>\n",
       "      <th>Spayed Female</th>\n",
       "      <th>Intact Male</th>\n",
       "      <th>Intact Female</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Mix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.973624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.396515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.421532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.396515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.973624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.059276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.471381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.714351</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.868974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.059276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Color  HasName  Month  Day  Hour  AgeuponOutcome  AnimalType  \\\n",
       "0  0.973624      1.0    2.0  1.0   3.0       -0.396515         0.0   \n",
       "1 -1.421532      1.0   10.0  1.0   2.0       -0.396515         1.0   \n",
       "2  0.973624      1.0    1.0  3.0   2.0       -0.059276         0.0   \n",
       "3 -1.471381      0.0    7.0  1.0   3.0       -0.714351         1.0   \n",
       "4 -0.868974      0.0   11.0  1.0   2.0       -0.059276         0.0   \n",
       "\n",
       "   Neutered Male  Spayed Female  Intact Male  Intact Female  Unknown  Mix  \n",
       "0            1.0            0.0          0.0            0.0      0.0  1.0  \n",
       "1            0.0            1.0          0.0            0.0      0.0  1.0  \n",
       "2            1.0            0.0          0.0            0.0      0.0  1.0  \n",
       "3            0.0            0.0          1.0            0.0      0.0  1.0  \n",
       "4            1.0            0.0          0.0            0.0      0.0  1.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.concat([X_train1,X_train_prepared], axis = 1)\n",
    "X_test = pd.concat([X_test1,X_test_prepared], axis = 1)\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "      <th>HasName</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>Neutered Male</th>\n",
       "      <th>Spayed Female</th>\n",
       "      <th>Intact Male</th>\n",
       "      <th>Intact Female</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Mix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.973624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.439590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.086797</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.042708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.936310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.382893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.294900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.609683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.973624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.042708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Color  HasName  Month  Day  Hour  AgeuponOutcome  AnimalType  \\\n",
       "0  0.973624      1.0   10.0  1.0   2.0       -0.439590         0.0   \n",
       "1  0.086797      1.0    7.0  3.0   2.0       -0.042708         0.0   \n",
       "2 -0.936310      1.0    1.0  1.0   2.0       -0.382893         1.0   \n",
       "3 -1.294900      1.0   12.0  3.0   3.0       -0.609683         0.0   \n",
       "4  0.973624      1.0    9.0  3.0   2.0       -0.042708         0.0   \n",
       "\n",
       "   Neutered Male  Spayed Female  Intact Male  Intact Female  Unknown  Mix  \n",
       "0            0.0            0.0          0.0            1.0      0.0  1.0  \n",
       "1            0.0            1.0          0.0            0.0      0.0  1.0  \n",
       "2            1.0            0.0          0.0            0.0      0.0  1.0  \n",
       "3            0.0            0.0          1.0            0.0      0.0  1.0  \n",
       "4            1.0            0.0          0.0            0.0      0.0  1.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model selection (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the target class as integers to use it\n",
    "with scikit-learn algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adoption' 'Died' 'Euthanasia' 'Return_to_owner' 'Transfer']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "target_label = LabelEncoder()\n",
    "y_train_label = target_label.fit_transform(y_train)\n",
    "print(target_label.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set\n",
    "\n",
    "To compare different models with each other, we can not use the test set, otherwise one would be tempted to keep the model corresponding best to the test set which could lead to overfitting.\n",
    "\n",
    "It is common to create a new set of the size of the test set, the  **validation** set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "Cross-validation is a useful method for comparing the performance of different machine learning models **without creating a validation set**.\n",
    "\n",
    "There are different types of cross-validation, the most classic procedure is:\n",
    "* Randomly divide the training set into two parts (90% / 10% for example).\n",
    "* Train the model on biggest part, and test it on the other part.\n",
    "* Repeat n times\n",
    "* Calculate the mean and standard deviation of the results\n",
    "\n",
    "The benefits are:\n",
    "* Consider the entire training set for the evaluation (without ignoring the data we would have use in the validation set)\n",
    "* Obtaining the standard deviation of the results allows a better evaluation of the model's accuracy.\n",
    "\n",
    "The main disadvantage is the computation time, since one carries out the learning of the model several times, this method can be impossible for datasets containing a large number of example (> 10e5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 2: StratifiedKFold (1 point)\n",
    "\n",
    "By observing the class distribution of the target attribute (using the pandas visualization functions), justify the use of the sklearn **StratifiedKFold** object for division of the training set when doing cross-validation instead of a pure **random** method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on what we've seen on the following four charts. The first two charts are built in the case of stratify. It could be observed that the proportion of each class in the training set is exactly the same as the validation set. On the other hand, the last two charts are built in the case of random method. We can see a difference on class proportions. For instance the proportion of the first class in the validation set is apparently larger than in the training set.  \n",
    "StratifiedKFold is used in order to ensure that the training and validation datasets each contain the same percentage of classes. This is very important because essentially we want to verify a model on a validation set that is able to represent the training set well. Otherwise, the validation would not be credential. Therefore, we should respect the proportion of each class in the validation set, which is apparently better than a random-sampling way in the sense of well-representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split( X_train, y_train_label, test_size=0.1, random_state=42,stratify=y_train_label)\n",
    "m_train=y_train_split.shape[0]\n",
    "m_test=y_test_split.shape[0]\n",
    "pd.DataFrame(y_train_split).hist(figsize=(5,5),weights=np.ones(m_train) / m_train)\n",
    "plt.title(\"Training set by Stratify \")\n",
    "pd.DataFrame(y_test_split).hist(figsize=(5,5),weights=np.ones(m_test)/m_test)\n",
    "plt.title(\"Validation set by Stratify \")\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split( X_train, y_train_label, test_size=0.1, random_state=42,stratify=None)\n",
    "m_train=y_train_split.shape[0]\n",
    "m_test=y_test_split.shape[0]\n",
    "pd.DataFrame(y_train_split).hist(figsize=(5,5),weights=np.ones(m_train) / m_train)\n",
    "plt.title(\"Training set by Random \")\n",
    "pd.DataFrame(y_test_split).hist(figsize=(5,5),weights=np.ones(m_test)/m_test)\n",
    "plt.title(\"Validation set by Random \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 16: (1 point)\n",
    "\n",
    "\n",
    "**Choose at least two models allowing the multiclass classification on sklearn in addition to the model implemented in the first part of the TP**.\n",
    "\n",
    "**Complete the compare function that performs the crossvalidation for different models and different metrics, and returns the list of averages and standard deviations for each of the metrics, for each of the models.**\n",
    "\n",
    "**Based on the different metrics, conclude on the best performing model.**\n",
    "\n",
    "Evaluate the models for the different metrics proposed:\n",
    "* **log loss**: this is the kaggle evaluation metric for this dataset\n",
    "* **precision**: corresponds to the quality of the prediction, the number of classes correctly predicted by the total prediction number\n",
    "* **recall**: the number of elements belonging to a class, identified as such, divided by the total number of elements of that class.\n",
    "* **f-score**: an average of accuracy and recall\n",
    "\n",
    "**Note: Precision and recall are two complementary measures for evaluating a multi-class classification model.**\n",
    "\n",
    "In the case of a binary classification with an important target class imbalance, (90% / 10%), evaluating the classification result with accuracy (number of correct predictions divided by the total number of predictions), a very good score (90% accuracy) can be obtained by choosing to systematically predict the majority class.\n",
    "\n",
    "In such a case, the precision would be high in the same way, but the recall would be very low, indicating the mediocrity of our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(models, X_train, y_train, nb_runs,scoring):\n",
    "    losses=[]\n",
    "    for m in models:\n",
    "        tmp_loss=cross_validate(m,X_train,y_train,cv=nb_runs,scoring=scoring)\n",
    "        losses.append(tmp_loss)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------\n",
      "\n",
      "The metric is test_neg_log_loss\n",
      "\n",
      "[-0.84949998 -0.85284408 -0.84163516]\n",
      "The metric is test_precision_macro\n",
      "\n",
      "[ 0.4779417   0.48996549  0.48305244]\n",
      "The metric is test_recall_macro\n",
      "\n",
      "[ 0.39690932  0.40521723  0.41888777]\n",
      "The metric is test_f1_macro\n",
      "\n",
      "[ 0.40356244  0.41093512  0.4248249 ]\n",
      "\n",
      "-------------------------\n",
      "\n",
      "The metric is test_neg_log_loss\n",
      "\n",
      "[-3.76886489 -4.03879518 -3.64085338]\n",
      "The metric is test_precision_macro\n",
      "\n",
      "[ 0.43022201  0.45799961  0.42619532]\n",
      "The metric is test_recall_macro\n",
      "\n",
      "[ 0.39783885  0.41827412  0.39584112]\n",
      "The metric is test_f1_macro\n",
      "\n",
      "[ 0.40576387  0.43107787  0.40426051]\n",
      "\n",
      "-------------------------\n",
      "\n",
      "The metric is test_neg_log_loss\n",
      "\n",
      "[-0.93864208 -0.97346392 -1.03437939]\n",
      "The metric is test_precision_macro\n",
      "\n",
      "[ 0.48939079  0.44659826  0.52138596]\n",
      "The metric is test_recall_macro\n",
      "\n",
      "[ 0.36216631  0.35705053  0.33100277]\n",
      "The metric is test_f1_macro\n",
      "\n",
      "[ 0.35766365  0.34792016  0.31972849]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "e:\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from SoftmaxClassifier import SoftmaxClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "y_train_label=y_train_label.reshape((y_train_label.shape[0],1))\n",
    "X_train=X_train.T\n",
    "nb_run = 3\n",
    "\n",
    "models = [\n",
    "\n",
    "    MLPClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SoftmaxClassifier()\n",
    "\n",
    "]\n",
    "scoring = ['neg_log_loss', 'precision_macro','recall_macro','f1_macro']\n",
    "losses=compare(models,X_train,y_train_label,nb_run,scoring)\n",
    "idx=['test_neg_log_loss','test_precision_macro','test_recall_macro','test_f1_macro']\n",
    "for m in losses:\n",
    "    print(\"\\n-------------------------\\n\")\n",
    "    for i in idx:\n",
    "        print (\"The metric is \"+ i+ \"\\n\")\n",
    "        print (m[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) negative log loss: Based on this measurement, MLPClassifier is the best since it has the least values.\n",
    "2) precision: The implemented SoftmaxRegression model seems to be the best even though MLPClassifier is very close.\n",
    "3) recall: MLPClassifier is the best because averagely it has the largest value, but RandomForestClassifier also works well.\n",
    "4) f1_score: MLPClassifier and RandomForestClassifier are the same good. Their f1_scores are very close to each other. \n",
    "Because of the above analysis, MLPClassifier is selected as the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 17: Confusion matrix (0.5 point)\n",
    "\n",
    "The confusion matrix A is such that $A_{i,j}$ represents the number of examples of class i classified as belonging to class j.\n",
    "\n",
    "Train the selected model on the entire training set.\n",
    "Using the confusion matrix and class distribution, analyze in more detail the performance of the chosen model and justify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Train selected model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "selected_model = MLPClassifier()\n",
    "model = selected_model.fit(X_train,y_train_label)\n",
    "y_pred=model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Died</th>\n",
       "      <th>Euthanasia</th>\n",
       "      <th>Return_to_owner</th>\n",
       "      <th>Transfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adoption</th>\n",
       "      <td>8765</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1276</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Died</th>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Euthanasia</th>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>358</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_to_owner</th>\n",
       "      <td>1821</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2400</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transfer</th>\n",
       "      <td>2029</td>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>831</td>\n",
       "      <td>6450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Adoption  Died  Euthanasia  Return_to_owner  Transfer\n",
       "Adoption             8765     1           9             1276       718\n",
       "Died                   17     7           9               16       148\n",
       "Euthanasia            208     0         258              358       731\n",
       "Return_to_owner      1821     0          19             2400       546\n",
       "Transfer             2029     3         109              831      6450"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(y_train_label, y_pred), columns = target_label.classes_, index = target_label.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Target class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adoption' 'Died' 'Euthanasia' 'Return_to_owner' 'Transfer']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x121c62390b8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "y_train_label=y_train_label.reshape((y_train_label.shape[0],))\n",
    "print(target_label.classes_)\n",
    "pd.Series(y_train_label).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 3: Hyper-parameters optimization (1 point)\n",
    "\n",
    "Hyper-parameters are the parameters set before the learning phase. To optimize the performance of the model, we can select the best hyper-parameters.\n",
    "\n",
    "Using sklearn, optimize the hyper-parameters of the model you have selected and show that the performance has been improved.\n",
    "For example, you can use: **GridSearchCV**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, make the prediction on the test set and give your results when submitting the lab.\n",
    "\n",
    "**Optional**: You can submit your results on kaggle and note your performance in terms of log loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = \n",
    "# pred_test = pd.Series(best_model.transform(X_test))\n",
    "# pred_test.to_csv(\"test_prediction.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
